{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmVtX1ZMVYMEP8bguKlUOn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bazgha19/Twitter-Opinion-Mining/blob/main/TwitterOpinionMining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install better-profanity"
      ],
      "metadata": {
        "id": "qb2U1oCytkJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tweepy\n",
        "\n",
        "from tweepy import OAuthHandler\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from better_profanity import profanity"
      ],
      "metadata": {
        "id": "DheQcfsOZ97b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consumer_key = 'Enter api key'\n",
        "consumer_secret = 'Enter api secret key'\n",
        "access_token = 'Enter access token key'\n",
        "access_token_secret = 'Enter access token secret key'"
      ],
      "metadata": {
        "id": "ClQvNrrBaGDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access Twitter Data\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "rGPTB6MGhS8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input a query from the user\n",
        "\n",
        "query = input(\"Please enter your topic / person of interest: \")\n",
        "\n",
        "# Filter the query to remove retweets\n",
        "\n",
        "filtered = query + \"-filter:retweets\"\n",
        "\n",
        "# Generate the latest tweets on the given query\n",
        "tweets = tweepy.Cursor(api.search_tweets,q=filtered,lang=\"en\").items(100)\n",
        "\n",
        "# Create a list of the tweets, the users, and their location\n",
        "list1 = [[tweet.text, tweet.user.screen_name, tweet.user.location] for tweet in tweets]\n",
        "\n",
        "# Convert the list into a dataframe\n",
        "df = pd.DataFrame(data=list1,columns=['tweets','user', \"location\"])\n",
        "\n",
        "# Convert only the tweets into a list\n",
        "tweet_list = df.tweets.to_list()"
      ],
      "metadata": {
        "id": "ln2fpq-erUZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to clean the tweets. Remove profanity, unnecessary characters, spaces, and stopwords.\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    if type(tweet) == np.float:\n",
        "        return \"\"\n",
        "    r = tweet.lower()\n",
        "    r = profanity.censor(r)\n",
        "    r = re.sub(\"'\", \"\", r) # This is to avoid removing contractions in english\n",
        "    r = re.sub(\"@[A-Za-z0-9_]+\",\"\", r)\n",
        "    r = re.sub(\"#[A-Za-z0-9_]+\",\"\", r)\n",
        "    r = re.sub(r'http\\S+', '', r)\n",
        "    r = re.sub('[()!?]', ' ', r)\n",
        "    r = re.sub('\\[.*?\\]',' ', r)\n",
        "    r = re.sub(\"[^a-z0-9]\",\" \", r)\n",
        "    r = r.split()\n",
        "    stopwords = [\"for\", \"on\", \"an\", \"a\", \"of\", \"and\", \"in\", \"the\", \"to\", \"from\"]\n",
        "    r = [w for w in r if not w in stopwords]\n",
        "    r = \" \".join(word for word in r)\n",
        "    return r"
      ],
      "metadata": {
        "id": "E9IDBPgeiUtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = [clean_tweet(tw) for tw in tweet_list]\n",
        "cleaned"
      ],
      "metadata": {
        "id": "S9S55-4Rrd0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sentiment objects using TextBlob\n",
        "\n",
        "sentiment_objects = [TextBlob(tweet) for tweet in cleaned]\n",
        "\n",
        "sentiment_objects[0].polarity, sentiment_objects[0]\n",
        "\n",
        "# Create a list of polarity values and tweet text\n",
        "sentiment_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in sentiment_objects]\n",
        "\n",
        "# Print the value of the 0th row.\n",
        "sentiment_values[0]\n",
        "\n",
        "# Print all the sentiment values\n",
        "sentiment_values[0:99]\n",
        "\n",
        "# Create a dataframe of each tweet against its polarity\n",
        "sentiment_df = pd.DataFrame(sentiment_values, columns=[\"polarity\", \"tweet\"])\n",
        "\n",
        "sentiment_df\n",
        "\n",
        "# Save the polarity column as 'n'.\n",
        "n=sentiment_df[\"polarity\"]\n",
        "\n",
        "# Convert this column into a series, 'm'.\n",
        "m=pd.Series(n)\n",
        "\n",
        "m\n",
        "\n",
        "# Initialize variables, 'pos', 'neg', 'neu'.\n",
        "\n",
        "pos=0\n",
        "neg=0\n",
        "neu=0\n",
        "\n",
        "# Create a loop to classify the tweets as Positive, Negative, or Neutral.\n",
        "# Count the number of each.\n",
        "\n",
        "for items in m:\n",
        "    if items>0:\n",
        "        print(\"Positive\")\n",
        "        pos=pos+1\n",
        "    elif items<0:\n",
        "        print(\"Negative\")\n",
        "        neg=neg+1\n",
        "    else:\n",
        "        print(\"Neutral\")\n",
        "        neu=neu+1\n",
        "\n",
        "print(pos,neg,neu)\n",
        "\n",
        "pieLabels=[\"Positive\",\"Negative\",\"Neutral\"]\n",
        "\n",
        "populationShare=[pos,neg,neu]\n",
        "\n",
        "figureObject, axesObject = plt.subplots()\n",
        "\n",
        "axesObject.pie(populationShare,labels=pieLabels,autopct='%1.2f',startangle=90)\n",
        "\n",
        "axesObject.axis('equal')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Display the number of twitter users who feel a certain way about the given topic.\n",
        "\n",
        "print(\"%f percent of twitter users feel positive about %s\"%(pos,query))\n",
        "\n",
        "print(\"%f percent of twitter users feel negative about %s\"%(neg,query))\n",
        "\n",
        "print(\"%f percent of twitter users feel neutral about %s\"%(neu,query))\n",
        "\n",
        "# Create a Wordcloud from the tweets\n",
        "\n",
        "all_words = ' '.join([text for text in cleaned])\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SaYaVwxdroQg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}